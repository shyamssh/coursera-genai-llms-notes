# Notes from Coursera course on generative-ai-with-llms

This repository contains high level notes with screenshots from the online course.
https://www.deeplearning.ai/courses/generative-ai-with-llms/

## Repository Contents

This repository has few readme files containing my notes as follows:

### ![1. llm-pre-training.md](./llm-pre-training.md) 
- **LLMs Pre-training:** Various types of pre-training methods for large language models including Autoencoding, Autoregressive, and Seq-to-Seq.
- **Scaling Model Training:** How to scale model training across multiple GPUs using methods like Distributed Data-Parallel (DDP) and Fully Sharded Data Parallel (FSDP).
- **Quantization:** Quantization on memory consumption during model training.
- **Scaling Laws and Compute Optimal Models:** Discussion about the Chinchilla paper, compute budget, scaling choices, and future trends.
